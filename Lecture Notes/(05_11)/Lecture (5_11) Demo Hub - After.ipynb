{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4f0a85",
   "metadata": {},
   "source": [
    "# Importing our modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e6bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *\n",
    "import math as m\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "056a01a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>diagnosis</th> <th>radius_mean</th> <th>texture_mean</th> <th>perimeter_mean</th> <th>area_mean</th> <th>smoothness_mean</th> <th>compactness_mean</th> <th>concavity_mean</th> <th>concave points_mean</th> <th>symmetry_mean</th> <th>fractal_dimension_mean</th> <th>radius_se</th> <th>texture_se</th> <th>perimeter_se</th> <th>area_se</th> <th>smoothness_se</th> <th>compactness_se</th> <th>concavity_se</th> <th>concave points_se</th> <th>symmetry_se</th> <th>fractal_dimension_se</th> <th>radius_worst</th> <th>texture_worst</th> <th>perimeter_worst</th> <th>area_worst</th> <th>smoothness_worst</th> <th>compactness_worst</th> <th>concavity_worst</th> <th>concave points_worst</th> <th>symmetry_worst</th> <th>fractal_dimension_worst</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>M        </td> <td>17.99      </td> <td>10.38       </td> <td>122.8         </td> <td>1001     </td> <td>0.1184         </td> <td>0.2776          </td> <td>0.3001        </td> <td>0.1471             </td> <td>0.2419       </td> <td>0.07871               </td> <td>1.095    </td> <td>0.9053    </td> <td>8.589       </td> <td>153.4  </td> <td>0.006399     </td> <td>0.04904       </td> <td>0.05373     </td> <td>0.01587          </td> <td>0.03003    </td> <td>0.006193            </td> <td>25.38       </td> <td>17.33        </td> <td>184.6          </td> <td>2019      </td> <td>0.1622          </td> <td>0.6656           </td> <td>0.7119         </td> <td>0.2654              </td> <td>0.4601        </td> <td>0.1189                 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>M        </td> <td>20.57      </td> <td>17.77       </td> <td>132.9         </td> <td>1326     </td> <td>0.08474        </td> <td>0.07864         </td> <td>0.0869        </td> <td>0.07017            </td> <td>0.1812       </td> <td>0.05667               </td> <td>0.5435   </td> <td>0.7339    </td> <td>3.398       </td> <td>74.08  </td> <td>0.005225     </td> <td>0.01308       </td> <td>0.0186      </td> <td>0.0134           </td> <td>0.01389    </td> <td>0.003532            </td> <td>24.99       </td> <td>23.41        </td> <td>158.8          </td> <td>1956      </td> <td>0.1238          </td> <td>0.1866           </td> <td>0.2416         </td> <td>0.186               </td> <td>0.275         </td> <td>0.08902                </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>M        </td> <td>19.69      </td> <td>21.25       </td> <td>130           </td> <td>1203     </td> <td>0.1096         </td> <td>0.1599          </td> <td>0.1974        </td> <td>0.1279             </td> <td>0.2069       </td> <td>0.05999               </td> <td>0.7456   </td> <td>0.7869    </td> <td>4.585       </td> <td>94.03  </td> <td>0.00615      </td> <td>0.04006       </td> <td>0.03832     </td> <td>0.02058          </td> <td>0.0225     </td> <td>0.004571            </td> <td>23.57       </td> <td>25.53        </td> <td>152.5          </td> <td>1709      </td> <td>0.1444          </td> <td>0.4245           </td> <td>0.4504         </td> <td>0.243               </td> <td>0.3613        </td> <td>0.08758                </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>M        </td> <td>11.42      </td> <td>20.38       </td> <td>77.58         </td> <td>386.1    </td> <td>0.1425         </td> <td>0.2839          </td> <td>0.2414        </td> <td>0.1052             </td> <td>0.2597       </td> <td>0.09744               </td> <td>0.4956   </td> <td>1.156     </td> <td>3.445       </td> <td>27.23  </td> <td>0.00911      </td> <td>0.07458       </td> <td>0.05661     </td> <td>0.01867          </td> <td>0.05963    </td> <td>0.009208            </td> <td>14.91       </td> <td>26.5         </td> <td>98.87          </td> <td>567.7     </td> <td>0.2098          </td> <td>0.8663           </td> <td>0.6869         </td> <td>0.2575              </td> <td>0.6638        </td> <td>0.173                  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>M        </td> <td>20.29      </td> <td>14.34       </td> <td>135.1         </td> <td>1297     </td> <td>0.1003         </td> <td>0.1328          </td> <td>0.198         </td> <td>0.1043             </td> <td>0.1809       </td> <td>0.05883               </td> <td>0.7572   </td> <td>0.7813    </td> <td>5.438       </td> <td>94.44  </td> <td>0.01149      </td> <td>0.02461       </td> <td>0.05688     </td> <td>0.01885          </td> <td>0.01756    </td> <td>0.005115            </td> <td>22.54       </td> <td>16.67        </td> <td>152.2          </td> <td>1575      </td> <td>0.1374          </td> <td>0.205            </td> <td>0.4            </td> <td>0.1625              </td> <td>0.2364        </td> <td>0.07678                </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>M        </td> <td>12.45      </td> <td>15.7        </td> <td>82.57         </td> <td>477.1    </td> <td>0.1278         </td> <td>0.17            </td> <td>0.1578        </td> <td>0.08089            </td> <td>0.2087       </td> <td>0.07613               </td> <td>0.3345   </td> <td>0.8902    </td> <td>2.217       </td> <td>27.19  </td> <td>0.00751      </td> <td>0.03345       </td> <td>0.03672     </td> <td>0.01137          </td> <td>0.02165    </td> <td>0.005082            </td> <td>15.47       </td> <td>23.75        </td> <td>103.4          </td> <td>741.6     </td> <td>0.1791          </td> <td>0.5249           </td> <td>0.5355         </td> <td>0.1741              </td> <td>0.3985        </td> <td>0.1244                 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>M        </td> <td>18.25      </td> <td>19.98       </td> <td>119.6         </td> <td>1040     </td> <td>0.09463        </td> <td>0.109           </td> <td>0.1127        </td> <td>0.074              </td> <td>0.1794       </td> <td>0.05742               </td> <td>0.4467   </td> <td>0.7732    </td> <td>3.18        </td> <td>53.91  </td> <td>0.004314     </td> <td>0.01382       </td> <td>0.02254     </td> <td>0.01039          </td> <td>0.01369    </td> <td>0.002179            </td> <td>22.88       </td> <td>27.66        </td> <td>153.2          </td> <td>1606      </td> <td>0.1442          </td> <td>0.2576           </td> <td>0.3784         </td> <td>0.1932              </td> <td>0.3063        </td> <td>0.08368                </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>M        </td> <td>13.71      </td> <td>20.83       </td> <td>90.2          </td> <td>577.9    </td> <td>0.1189         </td> <td>0.1645          </td> <td>0.09366       </td> <td>0.05985            </td> <td>0.2196       </td> <td>0.07451               </td> <td>0.5835   </td> <td>1.377     </td> <td>3.856       </td> <td>50.96  </td> <td>0.008805     </td> <td>0.03029       </td> <td>0.02488     </td> <td>0.01448          </td> <td>0.01486    </td> <td>0.005412            </td> <td>17.06       </td> <td>28.14        </td> <td>110.6          </td> <td>897       </td> <td>0.1654          </td> <td>0.3682           </td> <td>0.2678         </td> <td>0.1556              </td> <td>0.3196        </td> <td>0.1151                 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>M        </td> <td>13         </td> <td>21.82       </td> <td>87.5          </td> <td>519.8    </td> <td>0.1273         </td> <td>0.1932          </td> <td>0.1859        </td> <td>0.09353            </td> <td>0.235        </td> <td>0.07389               </td> <td>0.3063   </td> <td>1.002     </td> <td>2.406       </td> <td>24.32  </td> <td>0.005731     </td> <td>0.03502       </td> <td>0.03553     </td> <td>0.01226          </td> <td>0.02143    </td> <td>0.003749            </td> <td>15.49       </td> <td>30.73        </td> <td>106.2          </td> <td>739.3     </td> <td>0.1703          </td> <td>0.5401           </td> <td>0.539          </td> <td>0.206               </td> <td>0.4378        </td> <td>0.1072                 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>M        </td> <td>12.46      </td> <td>24.04       </td> <td>83.97         </td> <td>475.9    </td> <td>0.1186         </td> <td>0.2396          </td> <td>0.2273        </td> <td>0.08543            </td> <td>0.203        </td> <td>0.08243               </td> <td>0.2976   </td> <td>1.599     </td> <td>2.039       </td> <td>23.94  </td> <td>0.007149     </td> <td>0.07217       </td> <td>0.07743     </td> <td>0.01432          </td> <td>0.01789    </td> <td>0.01008             </td> <td>15.09       </td> <td>40.68        </td> <td>97.65          </td> <td>711.4     </td> <td>0.1853          </td> <td>1.058            </td> <td>1.105          </td> <td>0.221               </td> <td>0.4366        </td> <td>0.2075                 </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (559 rows omitted)</p>"
      ],
      "text/plain": [
       "diagnosis | radius_mean | texture_mean | perimeter_mean | area_mean | smoothness_mean | compactness_mean | concavity_mean | concave points_mean | symmetry_mean | fractal_dimension_mean | radius_se | texture_se | perimeter_se | area_se | smoothness_se | compactness_se | concavity_se | concave points_se | symmetry_se | fractal_dimension_se | radius_worst | texture_worst | perimeter_worst | area_worst | smoothness_worst | compactness_worst | concavity_worst | concave points_worst | symmetry_worst | fractal_dimension_worst\n",
       "M         | 17.99       | 10.38        | 122.8          | 1001      | 0.1184          | 0.2776           | 0.3001         | 0.1471              | 0.2419        | 0.07871                | 1.095     | 0.9053     | 8.589        | 153.4   | 0.006399      | 0.04904        | 0.05373      | 0.01587           | 0.03003     | 0.006193             | 25.38        | 17.33         | 184.6           | 2019       | 0.1622           | 0.6656            | 0.7119          | 0.2654               | 0.4601         | 0.1189\n",
       "M         | 20.57       | 17.77        | 132.9          | 1326      | 0.08474         | 0.07864          | 0.0869         | 0.07017             | 0.1812        | 0.05667                | 0.5435    | 0.7339     | 3.398        | 74.08   | 0.005225      | 0.01308        | 0.0186       | 0.0134            | 0.01389     | 0.003532             | 24.99        | 23.41         | 158.8           | 1956       | 0.1238           | 0.1866            | 0.2416          | 0.186                | 0.275          | 0.08902\n",
       "M         | 19.69       | 21.25        | 130            | 1203      | 0.1096          | 0.1599           | 0.1974         | 0.1279              | 0.2069        | 0.05999                | 0.7456    | 0.7869     | 4.585        | 94.03   | 0.00615       | 0.04006        | 0.03832      | 0.02058           | 0.0225      | 0.004571             | 23.57        | 25.53         | 152.5           | 1709       | 0.1444           | 0.4245            | 0.4504          | 0.243                | 0.3613         | 0.08758\n",
       "M         | 11.42       | 20.38        | 77.58          | 386.1     | 0.1425          | 0.2839           | 0.2414         | 0.1052              | 0.2597        | 0.09744                | 0.4956    | 1.156      | 3.445        | 27.23   | 0.00911       | 0.07458        | 0.05661      | 0.01867           | 0.05963     | 0.009208             | 14.91        | 26.5          | 98.87           | 567.7      | 0.2098           | 0.8663            | 0.6869          | 0.2575               | 0.6638         | 0.173\n",
       "M         | 20.29       | 14.34        | 135.1          | 1297      | 0.1003          | 0.1328           | 0.198          | 0.1043              | 0.1809        | 0.05883                | 0.7572    | 0.7813     | 5.438        | 94.44   | 0.01149       | 0.02461        | 0.05688      | 0.01885           | 0.01756     | 0.005115             | 22.54        | 16.67         | 152.2           | 1575       | 0.1374           | 0.205             | 0.4             | 0.1625               | 0.2364         | 0.07678\n",
       "M         | 12.45       | 15.7         | 82.57          | 477.1     | 0.1278          | 0.17             | 0.1578         | 0.08089             | 0.2087        | 0.07613                | 0.3345    | 0.8902     | 2.217        | 27.19   | 0.00751       | 0.03345        | 0.03672      | 0.01137           | 0.02165     | 0.005082             | 15.47        | 23.75         | 103.4           | 741.6      | 0.1791           | 0.5249            | 0.5355          | 0.1741               | 0.3985         | 0.1244\n",
       "M         | 18.25       | 19.98        | 119.6          | 1040      | 0.09463         | 0.109            | 0.1127         | 0.074               | 0.1794        | 0.05742                | 0.4467    | 0.7732     | 3.18         | 53.91   | 0.004314      | 0.01382        | 0.02254      | 0.01039           | 0.01369     | 0.002179             | 22.88        | 27.66         | 153.2           | 1606       | 0.1442           | 0.2576            | 0.3784          | 0.1932               | 0.3063         | 0.08368\n",
       "M         | 13.71       | 20.83        | 90.2           | 577.9     | 0.1189          | 0.1645           | 0.09366        | 0.05985             | 0.2196        | 0.07451                | 0.5835    | 1.377      | 3.856        | 50.96   | 0.008805      | 0.03029        | 0.02488      | 0.01448           | 0.01486     | 0.005412             | 17.06        | 28.14         | 110.6           | 897        | 0.1654           | 0.3682            | 0.2678          | 0.1556               | 0.3196         | 0.1151\n",
       "M         | 13          | 21.82        | 87.5           | 519.8     | 0.1273          | 0.1932           | 0.1859         | 0.09353             | 0.235         | 0.07389                | 0.3063    | 1.002      | 2.406        | 24.32   | 0.005731      | 0.03502        | 0.03553      | 0.01226           | 0.02143     | 0.003749             | 15.49        | 30.73         | 106.2           | 739.3      | 0.1703           | 0.5401            | 0.539           | 0.206                | 0.4378         | 0.1072\n",
       "M         | 12.46       | 24.04        | 83.97          | 475.9     | 0.1186          | 0.2396           | 0.2273         | 0.08543             | 0.203         | 0.08243                | 0.2976    | 1.599      | 2.039        | 23.94   | 0.007149      | 0.07217        | 0.07743      | 0.01432           | 0.01789     | 0.01008              | 15.09        | 40.68         | 97.65           | 711.4      | 0.1853           | 1.058             | 1.105           | 0.221                | 0.4366         | 0.2075\n",
       "... (559 rows omitted)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumor_data = Table.read_table(\"data.csv\").drop('id','Unnamed: 32')\n",
    "tumor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b3d43b",
   "metadata": {},
   "source": [
    "# Let's take a look at ScatterPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c74ee93a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tumor_labels = list(tumor_data.labels)\n",
    "tumor_attribute_list = tumor_labels[1:]\n",
    "tumor_attribute_array = tumor_attribute_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba2393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caution, this will crash the kernel due to the volume of outputs. \n",
    "\n",
    "for x in tumor_attribute_list:\n",
    "    tumor_attribute_list.remove(x)\n",
    "    for y in tumor_attribute_list:\n",
    "        tumor_data.scatter(x,y,group='diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e345e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reduces the list of attributes to examine the means only, to avoid crashing the kernel. \n",
    "tumor_labels = list(tumor_data.labels)\n",
    "tumor_attribute_list_means_only = tumor_labels[1:11]\n",
    "tumor_attribute_array_means_only = tumor_attribute_list_means_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77140f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This reduces the list of attributes to examine the means only, to avoid crashing the kernel. \n",
    "for x in tumor_attribute_list_means_only:\n",
    "    tumor_attribute_list_means_only.remove(x)\n",
    "    for y in tumor_attribute_list_means_only:\n",
    "        tumor_data.scatter(x,y,group='diagnosis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cc9d1",
   "metadata": {},
   "source": [
    "# Steps covered in (5/09) lecture, now defined as functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6546910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below will take a table, and a number as inputs. \n",
    "# Then the function will randomly shuffle the rows of the table and take the input number of rows for the training set. \n",
    "# The remaining rows will be stored as the test set. \n",
    "# The function returns both the training set and the test set. \n",
    "\n",
    "def train_test_separation(tbl,num_for_train):\n",
    "    shuffled_tbl = tbl.sample(with_replacement = False)\n",
    "    \n",
    "    train_tbl = shuffled_tbl.take(np.arange(num_for_train))\n",
    "    test_tbl = shuffled_tbl.take(np.arange(num_for_train,tbl.num_rows))\n",
    "    \n",
    "    print(\"Training set:\\t\",   train_tbl.num_rows, \"examples\")\n",
    "    print(\"Test set:\\t\",       test_tbl.num_rows, \"examples\")\n",
    "    \n",
    "    return train_tbl, test_tbl\n",
    "\n",
    "# The function below will take in two arrays of numbers as inputs. \n",
    "# It will then compute the Euclidean distance between the those two arrays as an output. \n",
    "\n",
    "def distance(array_one,array_two):\n",
    "    return (sum((array_one - array_two)**2))**(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a414d70c",
   "metadata": {},
   "source": [
    "#### The following function below is defined for you homework 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07713eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row (input): a row from the table \n",
    "# features (input): an array of column labels. These labels are the attributes that will help us classify individuals. \n",
    "# Note: the attributes must be numerical to help us pass them through the distance function defined above. \n",
    "\n",
    "def row_to_array(row, features):\n",
    "    \"\"\"Converts a row to an array of its features.\"\"\"\n",
    "    arr = make_array()\n",
    "    for feature in features:\n",
    "        arr = np.append(arr, row.item(feature))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac99e9b",
   "metadata": {},
   "source": [
    "# Let's classify these tumor cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef73b49",
   "metadata": {},
   "source": [
    "## Finding the `k` Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4918bb5",
   "metadata": {},
   "source": [
    "### Some pre-formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "863019f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\t 450 examples\n",
      "Test set:\t 119 examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_separation(tumor_data,450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53457484",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_test = test.row(0)\n",
    "row_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_array = row_to_array(row_to_test,tumor_attribute_array)\n",
    "test_features_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95cb43",
   "metadata": {},
   "source": [
    "### Find the distance between the example (i.e. test row) and each example in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9806361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will store the distance between the test row with all the rows in the training set. \n",
    "distances = make_array()\n",
    "\n",
    "# we will iterate through the training set row by row.  \n",
    "for train_row in train.rows:\n",
    "    #convert the train_row into an array also\n",
    "    train_row_array = row_to_array(train_row,tumor_attribute_array)\n",
    "    # compute the distance between the test row array and test row array\n",
    "    distance_test_to_train = distance(train_row_array, test_features_array)\n",
    "    # save the distance between these two arrays (test row and train row) into the distances array\n",
    "    distances = np.append(distances,distance_test_to_train)\n",
    "    \n",
    "\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ff217",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.take(0).show()\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0034901",
   "metadata": {},
   "source": [
    "### Augment the training data table with a column containing all the distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b2e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_distances = train.with_columns('Distances',distances)\n",
    "train_with_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7feaa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_distances.select('diagnosis','Distances').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d9032",
   "metadata": {},
   "source": [
    "### Sort the augmented table in increasing order of the distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_training = train_with_distances.sort('Distances')\n",
    "sorted_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcef85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e875fb75",
   "metadata": {},
   "source": [
    "### Take the top `k` rows of the sorted table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506da356",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_training = sorted_training.take(np.arange(11))\n",
    "top_k_training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d29d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09b6ffa9",
   "metadata": {},
   "source": [
    "## The Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37453d4",
   "metadata": {},
   "source": [
    "### Take a majority vote of the `k` nearest neighbors to see which of the two classes appear most often (visually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ed8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_training.scatter('radius_mean','compactness_mean',group = 'diagnosis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c862a55",
   "metadata": {},
   "source": [
    "### Take a majority vote of the `k` nearest neighbors to see which of the two classes appear most often (algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e3a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.row(0).item('diagnosis')\n",
    "\n",
    "top_k_training.group('diagnosis').sort('count',descending = True).column('diagnosis').item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ea5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c37bea13",
   "metadata": {},
   "source": [
    "# Evaluating your classifier (Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d408909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = make_array()\n",
    "\n",
    "for test_row in test.rows:\n",
    "    test_features_array = row_to_array(test_row,tumor_attribute_array)\n",
    "    distances = make_array()\n",
    "    \n",
    "    for train_row in train.rows:\n",
    "        train_row_array = row_to_array(train_row,tumor_attribute_array)\n",
    "        distance_test_to_train = distance(train_row_array, test_features_array)\n",
    "        distances = np.append(distances,distance_test_to_train)\n",
    "    \n",
    "    train_with_distances = train.with_columns('Distances',distances)\n",
    "    sorted_train = train_with_distances.sort('Distances')\n",
    "    k_nearest = sorted_train.take(np.arange(11)) #k = 11\n",
    "    most_common = k_nearest.group('diagnosis').sort('count',descending = True).column('diagnosis').item(0)\n",
    "    \n",
    "    classification = np.append(classification,most_common)\n",
    "    \n",
    "test = test.with_column('classification',classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aac80ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>diagnosis</th> <th>classification</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>B        </td> <td>B             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>B        </td> <td>B             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>M        </td> <td>B             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>M        </td> <td>M             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>B        </td> <td>B             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>B        </td> <td>B             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>B        </td> <td>B             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>B        </td> <td>B             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>B        </td> <td>B             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>B        </td> <td>B             </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (109 rows omitted)</p>"
      ],
      "text/plain": [
       "diagnosis | classification\n",
       "B         | B\n",
       "B         | B\n",
       "M         | B\n",
       "M         | M\n",
       "B         | B\n",
       "B         | B\n",
       "B         | B\n",
       "B         | B\n",
       "B         | B\n",
       "B         | B\n",
       "... (109 rows omitted)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.select('diagnosis','classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba4fbcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(test.column('diagnosis') == test.column('classification')) / test.num_rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
